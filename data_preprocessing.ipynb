{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import chardet  \n",
    "import re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' https://www.kaggle.com/datasets/kazanova/sentiment140/ '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Twitter Sentiment Dataset\n",
    "\"\"\" https://www.kaggle.com/datasets/kazanova/sentiment140/ \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%script` not found.\n"
     ]
    }
   ],
   "source": [
    "# Get the encoding for the twitter file\n",
    "%%script false\n",
    "\n",
    "# Detect the encoding\n",
    "with open('./Twitter Sentiment Data.csv', 'rb') as file:\n",
    "    result = chardet.detect(file.read())\n",
    "    encoding = result['encoding']\n",
    "\n",
    "# Write encoding to a file\n",
    "with open('encoding.txt', 'w') as f:\n",
    "    f.write(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   0       1600000 non-null  int64 \n",
      " 1   1       1600000 non-null  int64 \n",
      " 2   2       1600000 non-null  object\n",
      " 3   3       1600000 non-null  object\n",
      " 4   4       1600000 non-null  object\n",
      " 5   5       1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Twitter Dataset 1.6 Million Tweets\n",
    "# Put the tweet and target columns into a new file\n",
    "\n",
    "#read the encoding from the file\n",
    "with open('encoding.txt', 'r') as f:\n",
    "    encoding = f.read().strip()\n",
    "\n",
    "# Read the file with the detected encoding for the two important columns\n",
    "twitter_data = pd.read_csv('./Twitter Sentiment Data.csv', encoding=encoding, header=None)\n",
    "twitter_data.info() # Get Twitter Data Info\n",
    "\n",
    "# Get series of the tweets and targets\n",
    "x_data = twitter_data.iloc[:, -1] # tweets\n",
    "x_data.name = 'tweet'\n",
    "\n",
    "y_targets = twitter_data.iloc[:, 0] # target value (0, 4)\n",
    "y_targets.name = 'target'\n",
    "\n",
    "x_data.head()\n",
    "y_targets.head()\n",
    "\n",
    "new_twitter_data = pd.concat([x_data, y_targets], axis=1)\n",
    "new_twitter_data.to_csv('twitter_data_1600000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the range of dates from the tweets\n",
    "# earliest_date = twitter_data['date'].min()\n",
    "# latest_date = twitter_data['date'].max()\n",
    "# print(f\"Range: {earliest_date} - {latest_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:146\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:49\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+)\u001b[39m\u001b[38;5;124m\"\u001b[39m, tweet)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create a column which the unique hastags in each tweet\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m twitter_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhashtags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtwitter_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(extract_hashtags)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Create a list of all the hashtags\u001b[39;00m\n\u001b[1;32m     13\u001b[0m all_hashtags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(twitter_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhashtags\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), [])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "# Get the unique hashtags from each tweet and put it in the dataframe\n",
    "\n",
    "# Function to extract hashtags from a single tweet\n",
    "def extract_hashtags(tweet):\n",
    "    \n",
    "    # Find all the hashtags in the tweet (words that begin with '#')\n",
    "    return re.findall(r\"#(\\w+)\", tweet)\n",
    "\n",
    "# Create a column which the unique hastags in each tweet\n",
    "twitter_data['hashtags'] = twitter_data['text'].apply(extract_hashtags)\n",
    "\n",
    "# Create a list of all the hashtags\n",
    "all_hashtags = sum(twitter_data['hashtags'].tolist(), [])\n",
    "\n",
    "# Create a series with the unquie hashtags and their counts\n",
    "hashtag_series = pd.Series(all_hashtags)\n",
    "hashtag_counts = hashtag_series.value_counts()\n",
    "\n",
    "print(hashtag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 35847 entries, 83 to 1599999\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   target    35847 non-null  int64 \n",
      " 1   ids       35847 non-null  int64 \n",
      " 2   date      35847 non-null  object\n",
      " 3   flag      35847 non-null  object\n",
      " 4   user      35847 non-null  object\n",
      " 5   text      35847 non-null  object\n",
      " 6   hashtags  35847 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "mask = twitter_data['hashtags'].apply(lambda x: len(x) > 0)\n",
    "tweets_with_hashtags = twitter_data[mask]\n",
    "\n",
    "tweets_with_hashtags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Elon Musk's twitter data\n",
    "# Combine the date and tweets columns from each file into a new file\n",
    "\n",
    "# Base directory \n",
    "base_directory = './Elon Musk Tweet Data/'\n",
    "\n",
    "# Initialize a list to hold all the file paths\n",
    "file_paths = []\n",
    "\n",
    "# Loop over the range of years to construct file names\n",
    "for year in range(2010, 2023):\n",
    "    file_path = os.path.join(base_directory, f\"{year}.csv\") # Construct the file path\n",
    "    file_paths.append(file_path) # Append the file path to the list\n",
    "\n",
    "# print(file_paths, len(file_paths))\n",
    "\n",
    "# Create a dataframe for all values\n",
    "elon_tweets = pd.DataFrame(columns=['date', 'tweet'])\n",
    "\n",
    "# Loop list of files\n",
    "for file in file_paths:\n",
    "    df = pd.read_csv(file) # Read file\n",
    "    data = df[['date', 'tweet']] # Get the data and tweet columns\n",
    "    elon_tweets = pd.concat([elon_tweets, data], ignore_index=True) # append to new dataframe\n",
    "\n",
    "# Drop the repeating tweets, certain files have them\n",
    "elon_tweets.drop_duplicates(inplace=True)\n",
    "\n",
    "# Create a new file with all unique tweets from 2010-2022\n",
    "elon_tweets.to_csv('elon_musk_tweets_2010-2022.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
